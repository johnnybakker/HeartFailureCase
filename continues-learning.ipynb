{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Learning\n",
    "This notebook contains the code for a continues learning prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "Load the clean dataset and split it in half so that we can apply continuous learning on the second dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lead the clean dataset\n",
    "df = pd.read_csv(\"out/Clean.csv\", sep=\";\", decimal=\",\")\n",
    "\n",
    "# Drop non-numeric columns\n",
    "columns_to_drop = ['CaseNumber', 'LastName', 'PostCode']\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features from the target variable\n",
    "x = df.drop(columns='HeartDisease')\n",
    "y = df['HeartDisease']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "num_rows = len(x_train)\n",
    "\n",
    "# Split the train set into two equal halves\n",
    "train_x_1 = x_train\n",
    "train_y_1 = y_train\n",
    "\n",
    "# Transform the test records\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# Amount of test records\n",
    "test_len = len(x_test)\n",
    "\n",
    "# The first part of the test set is the test set that will be used to calculate the accuracy\n",
    "x_test_1 = x_test[:test_len // 2]\n",
    "y_test_1 = y_test[:test_len // 2]\n",
    "\n",
    "# The second part of the test set will be used to train the model further\n",
    "x_train_2 = x_test[test_len // 2:]\n",
    "y_train_2 = y_test[test_len // 2:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and export the model to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Model trained!\n",
      "Exporting model....\n",
      "Model exported!\n"
     ]
    }
   ],
   "source": [
    "# Train the KNN classifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "print(\"Training model...\")\n",
    "classifier.fit(train_x_1, train_y_1)\n",
    "print(\"Model trained!\")\n",
    "\n",
    "# export the model to a file\n",
    "print(\"Exporting model....\")\n",
    "joblib.dump(classifier, 'out/trained_model.mdl')\n",
    "classifier = None\n",
    "print(\"Model exported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the model from file and train further\n",
    "In the follow code snippet we will load the model back and calculate the accuracy of the first test set. When the accuracy is less than 80% the model will be trained further with train set 2. After the training is done we will calculate the accuracy again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model.....\n",
      "Model loaded!\n",
      "Accuracy: 84.7%\n",
      "Training model for a second time\n",
      "Accuracy after second training: 87.4%\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading model.....\")\n",
    "classifier = joblib.load('out/trained_model.mdl')\n",
    "print(\"Model loaded!\")\n",
    "\n",
    "pred_y_1 = classifier.predict(x_test_1)\n",
    "accuracy = np.sum(y_test_1 == pred_y_1) / len(y_test_1) * 100\n",
    "print(f\"Accuracy: {round(accuracy, 1)}%\")\n",
    "\n",
    "if accuracy < 90:\n",
    "\tprint(\"Training model for a second time\")\n",
    "\tclassifier.fit(x_train_2, y_train_2)\n",
    "\n",
    "pred_y_1 = classifier.predict(x_test_1)\n",
    "accuracy = np.sum(y_test_1 == pred_y_1) / len(y_test_1) * 100\n",
    "print(f\"Accuracy after second training: {round(accuracy, 1)}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
